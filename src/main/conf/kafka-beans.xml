<?xml version="1.0" encoding="UTF-8"?>
<beans xmlns="http://www.springframework.org/schema/beans"
       xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:p="http://www.springframework.org/schema/p"
       xmlns:mvc="http://www.springframework.org/schema/mvc" xmlns:context="http://www.springframework.org/schema/context"
       xmlns:util="http://www.springframework.org/schema/util"
       xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd
            http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.0.xsd
            http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-3.0.xsd
            http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util-3.0.xsd">


    <context:component-scan base-package="com.guosh.*" />

    <!--kafakaProducer 配置开始-->
    <bean id="producerProperties" class="java.util.HashMap">
        <constructor-arg>
            <map>
                <!-- kafka服务地址，可能是集群-->
                <entry key="bootstrap.servers" value="172.16.10.15:9092,172.16.10.15:9093,172.16.10.15:9094" />
                <!-- 有可能导致broker接收到重复的消息,默认值为3-->
                <entry key="retries" value="10" />
                <!-- 每次批量发送消息的数量-->
                <entry key="batch.size" value="1638" />
                <!-- 默认0ms，在异步IO线程被触发后（任何一个topic，partition满都可以触发）-->
                <entry key="linger.ms" value="1" />
                <!--producer可以用来缓存数据的内存大小。如果数据产生速度大于向broker发送的速度，producer会阻塞或者抛出异常 -->
                <entry key="buffer.memory" value="33554432 " />
                <!-- producer需要server接收到数据之后发出的确认接收的信号，此项配置就是指procuder需要多少个这样的确认信号-->
                <entry key="acks" value="all" />
                <entry key="key.serializer" value="org.apache.kafka.common.serialization.StringSerializer" />
                <entry key="value.serializer" value="org.apache.kafka.common.serialization.StringSerializer" />
            </map>
        </constructor-arg>
    </bean>
    <!-- 创建kafkatemplate需要使用的producerfactory bean -->
    <bean id="producerFactory"
          class="org.springframework.kafka.core.DefaultKafkaProducerFactory">
        <constructor-arg>
            <ref bean="producerProperties" />
        </constructor-arg>
    </bean>
    <!-- 创建kafkatemplate bean，使用的时候，只需要注入这个bean，即可使用template的send消息方法 -->
    <bean id="KafkaTemplate" class="org.springframework.kafka.core.KafkaTemplate">
        <constructor-arg ref="producerFactory" />
        <!--设置对应topic-->
        <property name="defaultTopic" value="tests" />
    </bean>
    <!--kafakaProducer 配置结束-->

    <!--kafakaConsumer 配置开始-->
    <bean id="consumerProperties" class="java.util.HashMap">
        <constructor-arg>
            <map>
                <!--Kafka服务地址 -->
                <entry key="bootstrap.servers" value="172.16.10.15:9092,172.16.10.15:9093,172.16.10.15:9094" />
                <!--Consumer的组ID，相同goup.id的consumer属于同一个组。 -->
                <entry key="group.id" value="order-beta" />
                <!--如果此值设置为true，consumer会周期性的把当前消费的offset值保存到zookeeper。当consumer失败重启之后将会使用此值作为新开始消费的值。 -->
                <entry key="enable.auto.commit" value="true" />
                <!--网络请求的socket超时时间。实际超时时间由max.fetch.wait + socket.timeout.ms 确定 -->
                <entry key="session.timeout.ms" value="15000 " />
                <entry key="key.deserializer"
                       value="org.apache.kafka.common.serialization.StringDeserializer" />
                <entry key="value.deserializer"
                       value="org.apache.kafka.common.serialization.StringDeserializer" />
            </map>
        </constructor-arg>
    </bean>
    <!--指定具体监听类的bean -->
    <bean id="messageListernerConsumerService" class="com.guosh.kafaka.KafakaConsumer" />
    <!-- 创建consumerFactory bean -->
    <bean id="consumerFactory" class="org.springframework.kafka.core.DefaultKafkaConsumerFactory">
        <constructor-arg>
            <ref bean="consumerProperties"/>
        </constructor-arg>
    </bean>

    <!--同时配置2个topic 创建2个的消费者容器，然后统一指向listner的消息处理类，统一让这个类进行后续业务处理-->
    <bean id="containerProperties" class="org.springframework.kafka.listener.config.ContainerProperties">
        <constructor-arg value="tests"/>
        <property name="messageListener" ref="messageListernerConsumerService"/>
    </bean>
    <bean id="containerProperties_topictest" class="org.springframework.kafka.listener.config.ContainerProperties">
    <constructor-arg value="topictest"/>
    <property name="messageListener" ref="messageListernerConsumerService"/>
</bean>

    <bean id="messageListenerContainer" class="org.springframework.kafka.listener.KafkaMessageListenerContainer" init-method="doStart">
        <constructor-arg ref="consumerFactory"/>
        <constructor-arg ref="containerProperties"/>
    </bean>
    <bean id="messageListenerContainer_topictest" class="org.springframework.kafka.listener.KafkaMessageListenerContainer" init-method="doStart">
        <constructor-arg ref="consumerFactory"/>
        <constructor-arg ref="containerProperties_topictest"/>
    </bean>
    <!--kafakaConsumer 配置结束-->
</beans>